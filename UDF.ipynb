{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# UDF: user-defined functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- User-defined functions are a way to bring the flexibility of the RDD to the data frame. They mimic the `.map()` part of working with RDDs.\n",
    "- `@F.udf(f, returnType)` decorator will promote a Python function to operate on columns of a data frame like the functions from `F`.\n",
    "- The original Python function is accessible through the `.func` attribute of a UDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Pandas UDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Series UDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Familirar column-first approach.\n",
    "- The default batch size is 10,000.\n",
    "- `spark.sql.execution.arrow.maxRecordsPerBatch` config option changes the maximum batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### *Series to Series* [aka Scalar]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Takes in a Column, converts it to a Series, returns a Series that is converted back to a Column.\n",
    "- Column functions, but in Pandas.\n",
    "- Almost the same as usual Python UDFs, but works in batches instead of one value at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Iterator of Series to Iterator of Series*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exactly the same as the previous, but with explicit iteration over batches of Series.\n",
    "- Also takes a Column and returns a Column.\n",
    "- Allows to improve performance when there is an *expensive cold start* (i.e., unpack an ML model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Iterator of Multiple Series to Iterator of Series*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can take multiple Columns as inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## UDFs on grouped data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split-apply-combine pattern: split the data using `.groupby()`, apply the function to each batch independently, combine the batches.\n",
    "- Each group has to be able to fit into a Pandas DataFrame on the executor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Group aggregate UDFs* [aka Series to Scalar]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distills the Series into a single value.\n",
    "- Basically a custom aggregate function.\n",
    "- Applied in `.groupby().agg()`. Each group becomes a batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### *Group map UDFs*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Iterates over batches of Pandas dat frames, yield Pandas data frames that are combined into a Spark data frame.\n",
    "- Do not need to be decorated, but are applied using `.groupby().applyInPandas()`.\n",
    "- The schema of the output has to be supplied as an argument.\n",
    "- If something needs to be applied to the entire data frame without splitting into groups, use `.mapInPandas()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Choosing which Pandas UDF to use\n",
    "- Do I need control over the splits of data into batches?\n",
    "  - *YES:* What will the UDF return?\n",
    "    - *A single aggregate value:* `Group Aggregate UDF`.\n",
    "    - *A transformed data frame* `Group Map UDF`.\n",
    "  - *NO:* Do I need the whole data or only some columns?\n",
    "    - *Complete data:* `mapInPandas()`\n",
    "    - *Columns are enough:* Do I need a cold start?\n",
    "      - *NO:* `Series to Series UDF`\n",
    "      - *YES:* How many columns do I need to use?\n",
    "        - *1:* `Iterator of Series to Iterator of Series UDF`\n",
    "        - *2+:* `Iterator of Multiple Series to Iterator of Series UDF`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pathlib\n",
    "import sys\n",
    "import time\n",
    "from typing import Iterator, Tuple\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "if (root := str(pathlib.Path().absolute().parent)) not in sys.path:\n",
    "    sys.path.append(root)\n",
    "\n",
    "import src\n",
    "import utilities\n",
    "\n",
    "utilities.setup_environment_for_spark()\n",
    "\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://pklis-ldrb00763.labiac.df.sbrf.ru:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1.3.5.3.1-1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>пе_пе</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f1af9cda880>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = utilities.get_spark_session(r\"пе_пе\", max_executors=35)\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_hdfs_dir = \"/arnsdpsbx/user/team/team_ss/ds_projects/mvs-key-channel-prediction/\"\n",
    "_hdfs_csv = f\"{_hdfs_dir}/interim/vsp_freeze_stats.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- epk_id: long (nullable = true)\n",
      " |-- hold_type: string (nullable = true)\n",
      " |-- score_sbp: float (nullable = true)\n",
      " |-- score_dkm: float (nullable = true)\n",
      " |-- sd_age_yrs_comp_nv: float (nullable = true)\n",
      "\n",
      "+-------------------+---------+----------+-----------+------------------+\n",
      "|             epk_id|hold_type| score_sbp|  score_dkm|sd_age_yrs_comp_nv|\n",
      "+-------------------+---------+----------+-----------+------------------+\n",
      "|1126087828843062099|   1_main| 0.4078902|  0.2693926|              39.0|\n",
      "|1126099244876979588|   1_main|0.11111562|0.064469524|              42.0|\n",
      "|1126100365869525512|   1_main| 0.2480534|  0.1110391|              49.0|\n",
      "+-------------------+---------+----------+-----------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = T.StructType(fields=[\n",
    "    T.StructField(\"epk_id\", T.LongType()),\n",
    "    T.StructField(\"hold_type\", T.StringType()),\n",
    "    T.StructField(\"score_sbp\", T.FloatType()),\n",
    "    T.StructField(\"score_dkm\", T.FloatType()),\n",
    "    T.StructField(\"sd_age_yrs_comp_nv\", T.FloatType()),\n",
    "])\n",
    "\n",
    "stats = spark.read.csv(_hdfs_csv, header=True, schema=schema)\n",
    "stats.printSchema()\n",
    "stats.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(returnType=T.StringType())\n",
    "def reverse_string(string: str) -> str:\n",
    "    \"\"\"Reverse a string.\"\"\"\n",
    "    return string[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+----------+-----------+------------------+-----------+\n",
      "|             epk_id|hold_type| score_sbp|  score_dkm|sd_age_yrs_comp_nv|hold_type_r|\n",
      "+-------------------+---------+----------+-----------+------------------+-----------+\n",
      "|1126087828843062099|   1_main| 0.4078902|  0.2693926|              39.0|     niam_1|\n",
      "|1126099244876979588|   1_main|0.11111562|0.064469524|              42.0|     niam_1|\n",
      "|1126100365869525512|   1_main| 0.2480534|  0.1110391|              49.0|     niam_1|\n",
      "|1126116274430575580|   1_main|0.33973783|  0.3550213|              42.0|     niam_1|\n",
      "|1126117223621958551|   1_main|0.48102745|  0.2877174|              35.0|     niam_1|\n",
      "|1126118383268436038|   1_main|0.35070643| 0.51856196|              62.0|     niam_1|\n",
      "|1126119341050728845|     3_zp|0.25619835|  0.2162769|              33.0|       pz_3|\n",
      "+-------------------+---------+----------+-----------+------------------+-----------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "stats.withColumn(\"hold_type_r\", reverse_string(\"hold_type\")).show(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series UDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Series*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.pandas_udf(returnType=T.DoubleType())\n",
    "def age_to_fahrenheit(age: pd.Series) -> pd.Series:\n",
    "    \"\"\"Transforms age to Fahrenheit (as if it was in Celsius).\"\"\"\n",
    "    return age * 9 / 5 + 32\n",
    "\n",
    "\n",
    "@F.pandas_udf(returnType=T.DoubleType())\n",
    "def shuffle_column(col: pd.Series) -> pd.Series:\n",
    "    \"\"\"Shuffle the values of the column for a permutation test.\"\"\"\n",
    "    return col.sample(frac=1, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+----------+-----------+------------------+------------------+\n",
      "|             epk_id|hold_type| score_sbp|  score_dkm|sd_age_yrs_comp_nv|             age_f|\n",
      "+-------------------+---------+----------+-----------+------------------+------------------+\n",
      "|1126087828843062099|   1_main| 0.4078902|  0.2693926|              39.0|102.19999694824219|\n",
      "|1126099244876979588|   1_main|0.11111562|0.064469524|              42.0| 107.5999984741211|\n",
      "|1126100365869525512|   1_main| 0.2480534|  0.1110391|              49.0|120.19999694824219|\n",
      "|1126116274430575580|   1_main|0.33973783|  0.3550213|              42.0| 107.5999984741211|\n",
      "|1126117223621958551|   1_main|0.48102745|  0.2877174|              35.0|              95.0|\n",
      "|1126118383268436038|   1_main|0.35070643| 0.51856196|              62.0|143.60000610351562|\n",
      "|1126119341050728845|     3_zp|0.25619835|  0.2162769|              33.0|  91.4000015258789|\n",
      "+-------------------+---------+----------+-----------+------------------+------------------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "stats.withColumn(\"age_f\", age_to_fahrenheit(F.col(\"sd_age_yrs_comp_nv\"))).show(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    102.199997\n",
       "1    107.599998\n",
       "2    120.199997\n",
       "3    107.599998\n",
       "4     95.000000\n",
       "Name: sd_age_yrs_comp_nv, dtype: float32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = stats.limit(5).toPandas()\n",
    "age_to_fahrenheit.func(sample.sd_age_yrs_comp_nv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Iterator of Series*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.pandas_udf(returnType=T.DoubleType())\n",
    "def age_to_fahrenheit(age: Iterator[pd.Series]) -> Iterator[pd.Series]:\n",
    "    \"\"\"Transforms age to Fahrenheit (as if it was in Celsius).\"\"\"\n",
    "\n",
    "    # Here can be an expensive cold start, that will happen once on each worker\n",
    "    # rather than once for every batch.\n",
    "    time.sleep(7)\n",
    "\n",
    "    for batch in age:\n",
    "        yield batch * 9 / 5 + 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+----------+-----------+------------------+------------------+\n",
      "|             epk_id|hold_type| score_sbp|  score_dkm|sd_age_yrs_comp_nv|             age_f|\n",
      "+-------------------+---------+----------+-----------+------------------+------------------+\n",
      "|1126087828843062099|   1_main| 0.4078902|  0.2693926|              39.0|102.19999694824219|\n",
      "|1126099244876979588|   1_main|0.11111562|0.064469524|              42.0| 107.5999984741211|\n",
      "|1126100365869525512|   1_main| 0.2480534|  0.1110391|              49.0|120.19999694824219|\n",
      "|1126116274430575580|   1_main|0.33973783|  0.3550213|              42.0| 107.5999984741211|\n",
      "|1126117223621958551|   1_main|0.48102745|  0.2877174|              35.0|              95.0|\n",
      "|1126118383268436038|   1_main|0.35070643| 0.51856196|              62.0|143.60000610351562|\n",
      "|1126119341050728845|     3_zp|0.25619835|  0.2162769|              33.0|  91.4000015258789|\n",
      "+-------------------+---------+----------+-----------+------------------+------------------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "stats.withColumn(\"age_f\", age_to_fahrenheit(F.col(\"sd_age_yrs_comp_nv\"))).show(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Iterator of Multiple Series*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.pandas_udf(returnType=T.DoubleType())\n",
    "def harmonic_mean(scores: Iterator[Tuple[pd.Series, pd.Series]]) -> Iterator[pd.Series]:\n",
    "    \"\"\"Compute the harmonic mean of two columns.\"\"\"\n",
    "\n",
    "    for sbp, dkm in scores:\n",
    "        yield 2 * sbp * dkm / (sbp + dkm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+----------+-----------+------------------+-------------------+\n",
      "|             epk_id|hold_type| score_sbp|  score_dkm|sd_age_yrs_comp_nv|                 hm|\n",
      "+-------------------+---------+----------+-----------+------------------+-------------------+\n",
      "|1126087828843062099|   1_main| 0.4078902|  0.2693926|              39.0|0.32448071241378784|\n",
      "|1126099244876979588|   1_main|0.11111562|0.064469524|              42.0|0.08159654587507248|\n",
      "|1126100365869525512|   1_main| 0.2480534|  0.1110391|              49.0|0.15340685844421387|\n",
      "|1126116274430575580|   1_main|0.33973783|  0.3550213|              42.0|0.34721145033836365|\n",
      "|1126117223621958551|   1_main|0.48102745|  0.2877174|              35.0| 0.3600673973560333|\n",
      "|1126118383268436038|   1_main|0.35070643| 0.51856196|              62.0| 0.4184277355670929|\n",
      "|1126119341050728845|     3_zp|0.25619835|  0.2162769|              33.0| 0.2345510721206665|\n",
      "+-------------------+---------+----------+-----------+------------------+-------------------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats.withColumn(\"hm\", harmonic_mean(F.col(\"score_sbp\"), F.col(\"score_dkm\"))).show(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group UDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.pandas_udf(returnType=T.DoubleType())\n",
    "def rate_of_change(age: pd.Series, score: pd.Series) -> float:\n",
    "    \"\"\"Fit a linear regression within the group and return the slope of the line.\"\"\"\n",
    "\n",
    "    reg = LinearRegression().fit(X=age.values.reshape(-1, 1), y=score)\n",
    "\n",
    "    return reg.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|hold_type|                rate|\n",
      "+---------+--------------------+\n",
      "|   1_main|-8.99054866749793...|\n",
      "|    2_lpr|-2.25336276344023...|\n",
      "|     3_zp|-0.00277369585819...|\n",
      "+---------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    stats.groupBy(\"hold_type\")\n",
    "    .agg(rate_of_change(\"sd_age_yrs_comp_nv\", \"score_sbp\").alias(\"rate\"))\n",
    "    .show(7)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `applyInPandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scale_age(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Min-max scale the age column.\"\"\"\n",
    "\n",
    "    age = df.sd_age_yrs_comp_nv\n",
    "    age_min, age_max = age.min(), age.max()\n",
    "    out = (age - age_min) / (age_max - age_min)\n",
    "    n = df.shape[0]\n",
    "\n",
    "    return df.drop(\"sd_age_yrs_comp_nv\", axis=\"columns\").assign(age_scaled=out, n=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epk_id</th>\n",
       "      <th>hold_type</th>\n",
       "      <th>score_sbp</th>\n",
       "      <th>score_dkm</th>\n",
       "      <th>age_scaled</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1126087828843062099</td>\n",
       "      <td>1_main</td>\n",
       "      <td>0.407890</td>\n",
       "      <td>0.269393</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1126099244876979588</td>\n",
       "      <td>1_main</td>\n",
       "      <td>0.111116</td>\n",
       "      <td>0.064470</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1126100365869525512</td>\n",
       "      <td>1_main</td>\n",
       "      <td>0.248053</td>\n",
       "      <td>0.111039</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1126116274430575580</td>\n",
       "      <td>1_main</td>\n",
       "      <td>0.339738</td>\n",
       "      <td>0.355021</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1126117223621958551</td>\n",
       "      <td>1_main</td>\n",
       "      <td>0.481027</td>\n",
       "      <td>0.287717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                epk_id hold_type  score_sbp  score_dkm  age_scaled  n\n",
       "0  1126087828843062099    1_main   0.407890   0.269393    0.285714  5\n",
       "1  1126099244876979588    1_main   0.111116   0.064470    0.500000  5\n",
       "2  1126100365869525512    1_main   0.248053   0.111039    1.000000  5\n",
       "3  1126116274430575580    1_main   0.339738   0.355021    0.500000  5\n",
       "4  1126117223621958551    1_main   0.481027   0.287717    0.000000  5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = stats.limit(5).toPandas()\n",
    "min_max_scale_age(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+-------------------+-------------------+-------------------+------+\n",
      "|             epk_id|hold_type|          score_sbp|          score_dkm|         age_scaled|     n|\n",
      "+-------------------+---------+-------------------+-------------------+-------------------+------+\n",
      "|1131576990673220011|   1_main|0.24425622820854187| 0.2018217295408249|0.40909090638160706|270000|\n",
      "|1131578133139453629|   1_main| 0.3485866189002991|0.14937470853328705| 0.5454545617103577|270000|\n",
      "|1131578889056964978|   1_main|0.27660831809043884|0.06328414380550385| 0.7272727489471436|270000|\n",
      "|1131579954213543423|   1_main| 0.2329607456922531| 0.2735936939716339| 0.8863636255264282|270000|\n",
      "|1131580607051412559|   1_main| 0.3482333719730377|0.38330310583114624| 0.3636363744735718|270000|\n",
      "|1131581006485048709|   1_main|0.18145854771137238|0.25156131386756897| 0.7045454382896423|270000|\n",
      "|1131581023664976379|   1_main| 0.6668580770492554|0.44185078144073486| 0.5454545617103577|270000|\n",
      "+-------------------+---------+-------------------+-------------------+-------------------+------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "schema = T.StructType(fields=[\n",
    "    T.StructField(\"epk_id\", T.LongType()),\n",
    "    T.StructField(\"hold_type\", T.StringType()),\n",
    "    T.StructField(\"score_sbp\", T.DoubleType()),\n",
    "    T.StructField(\"score_dkm\", T.DoubleType()),\n",
    "    T.StructField(\"age_scaled\", T.DoubleType()),\n",
    "    T.StructField(\"n\", T.IntegerType()),\n",
    "])\n",
    "\n",
    "(\n",
    "    stats.groupby(\"hold_type\")\n",
    "    .applyInPandas(min_max_scale_age, schema=schema)\n",
    "    .show(7)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|hold_type| count|\n",
      "+---------+------+\n",
      "|   1_main|270000|\n",
      "|     3_zp|  9810|\n",
      "|    2_lpr| 19143|\n",
      "+---------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "stats.groupby(\"hold_type\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `mapInPandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_scores(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Assign a group based on the score.\"\"\"\n",
    "\n",
    "    for batch_df in df:\n",
    "        batch_df[\"total_score\"] = batch_df[\"score_sbp\"] + batch_df[\"score_sbp\"]\n",
    "        batch_df[\"n\"] = batch_df.shape[0]\n",
    "        yield batch_df[[\"epk_id\", \"total_score\", \"n\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-----+\n",
      "|             epk_id|        total_score|    n|\n",
      "+-------------------+-------------------+-----+\n",
      "|1126087828843062099| 0.8157804012298584|10000|\n",
      "|1126099244876979588|0.22223123908042908|10000|\n",
      "|1126100365869525512| 0.4961068034172058|10000|\n",
      "|1126116274430575580| 0.6794756650924683|10000|\n",
      "|1126117223621958551| 0.9620549082756042|10000|\n",
      "|1126118383268436038| 0.7014128565788269|10000|\n",
      "|1126119341050728845| 0.5123966932296753|10000|\n",
      "+-------------------+-------------------+-----+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = T.StructType(fields=[\n",
    "    T.StructField(\"epk_id\", T.LongType()),\n",
    "    T.StructField(\"total_score\", T.DoubleType()),\n",
    "    T.StructField(\"n\", T.IntegerType()),\n",
    "])\n",
    "\n",
    "stats.mapInPandas(sum_scores, schema=schema).show(7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 (PYENV.MLPY388)",
   "language": "python",
   "name": "pyenv.mlpy388"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
